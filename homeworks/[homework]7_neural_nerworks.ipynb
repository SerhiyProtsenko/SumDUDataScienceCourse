{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BsP8X727kQMe"
   },
   "source": [
    "<p style=\"align: center;\"><img align=center src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\"  width=400></p>\n",
    "\n",
    "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-2rBvEkkQMj"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PHc7UePMkQMp"
   },
   "source": [
    "# Дисклеймер про CrossEntropyLoss и NLLLoss\n",
    "\n",
    "Обычно в PyTorch не нужно делать Softmax как последний слой модели. \n",
    "\n",
    "* Если Вы используете NLLLoss, то ему на вход надо давать лог вероятности, то есть выход слоя LogSoftmax. (Просто результат софтмакса, к которому применен логарифм)\n",
    "* Если Вы используете CrossEntropyLoss, то применение LogSoftmax уже включено внутрь лосса, поэтому ему на вход надо подавать просто выход обычного линейного слоя без активации. По сути CrossEntropyLoss = LogSoftmax + NLLLoss\n",
    "\n",
    "Зачем такие сложности, чтобы посчитать обычную кросс энтропию, которую мы использовали как лосс еще в логистической регрессии? Дело в том, что нам в любом случае придется взять логарифм от результатов софтмакса, а если делать это одной функцией, то можно сделать более устойчивую реализацию, которая даст меньшую вычислительную погрешность. \n",
    "\n",
    "Таким образом, если у вас в конце сети, решающей задачу классификации, стоит просто линейный слой без активации, то вам нужно использовать CrossEntropy. В этой домашке везде используется лосс CrossEntropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8rM9IY0YkQMq"
   },
   "source": [
    "# 1. Создайте генератор батчей. \n",
    "\n",
    "В этот раз мы хотим сделать генератор, который будет максимально похож на то, что используется в реальном обучении. \n",
    "\n",
    "С помощью numpy вам нужно перемешать исходную выборку и выбирать из нее батчи размером batch_size, если размер выборки не делился на размер батча, то последний батч должен иметь размер меньше batch_size и состоять просто из всех оставшихся объектов. Возвращать нужно в формате (X_batch, y_batch)\n",
    "\n",
    "\n",
    "**Ответ на задание - код**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ttf6PZuVkQMr"
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size):\n",
    "    np.random.seed(42)\n",
    "    perm = np.random.permutation(len(X))\n",
    "    \n",
    "    # YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJ9_3VfrkQMv"
   },
   "source": [
    "# 2. Обучите модель для классификации звезд\n",
    "\n",
    "Загрузите датасет из файла sky_data.csv, разделите его на train/test и обучите на нем нейронную сеть (архитектура ниже). Обучайте на батчах с помощью оптимизатора Adam со lr=1e-2. \n",
    "\n",
    "Архитектура:\n",
    "\n",
    "1. Dense Layer с relu активацией и 50 нейронами\n",
    "2. Dropout with 50% keep rate\n",
    "3. BatchNorm\n",
    "4. Dense Layer с relu активацией и 100 нейронами\n",
    "5. Dropout with 50% keep rate\n",
    "6. BatchNorm\n",
    "7. Выходной Dense слой c количеством нейронов, равному количеству классов\n",
    "\n",
    "Лосс - CrossEntropy.\n",
    "\n",
    "**В качестве ответа введите число - среднее предсказание 0 класса на тестовом датасете (т.е. выход модели для 0 класса, где среднее берется по предсказаниям для всех строчек из теста)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qTd7VFMskQMw"
   },
   "source": [
    "В датасете классы - строчки, поэтому чтобы ответ совпал с ответом на степике надо каким-то детерминированным образом его закаодировать. Для этого в строчке ниже объявлен dict, с помощью него и функции map превратите столбец с таргетом в целое число."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MTMs6bU6kQMx"
   },
   "source": [
    "Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ci8mdz99kQMy"
   },
   "outputs": [],
   "source": [
    "feature_columns = ['ra', 'dec', 'u', 'g', 'r', 'i', 'z', 'run', 'camcol', 'field']\n",
    "target_column = 'class'\n",
    "\n",
    "target_mapping = {\n",
    "    'GALAXY': 0,\n",
    "    'STAR': 1,\n",
    "    'QSO': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QRcIYVvUkQM2"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./sky_data.csv')\n",
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EVwCwA6RkQM5"
   },
   "outputs": [],
   "source": [
    "# Extract Features\n",
    "X = <YOUR CODE>\n",
    "# Extract target\n",
    "y = <YOUR CODE>\n",
    "\n",
    "# encode target with target_mapping\n",
    "y = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A3OkZT7HkQM7"
   },
   "source": [
    "Нормализация фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ynmXS7dMkQM8"
   },
   "outputs": [],
   "source": [
    "# Просто вычтите среднее и поделитe на стандартное отклонение\n",
    "X = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VTcR3q0SkQNj"
   },
   "source": [
    "Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m5AFbCY4kQNk"
   },
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "# Превратим данные в тензоры, чтобы потом было удобнее\n",
    "X_train = torch.FloatTensor(X_train.values)\n",
    "y_train = torch.LongTensor(y_train.values)\n",
    "X_test = torch.FloatTensor(X_test.values)\n",
    "y_test = torch.LongTensor(y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZDCt0vtlkQNo"
   },
   "source": [
    "Хорошо, данные мы подготовили, теперь надо объявить модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fI6ZqCaCkQNp"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42) \n",
    "np.random.seed(42)\n",
    "model = nn.Sequential(\n",
    "    <YOUR CODE>\n",
    ")\n",
    "    \n",
    "loss_fn = <YOUR CODE>\n",
    "optimizer = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GkUkeHfokQNs"
   },
   "source": [
    "Теперь обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41jYcT6AkQNt"
   },
   "outputs": [],
   "source": [
    "def train(num_epoch):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for i in range(num_epoch):\n",
    "        for X_batch, y_batch in batch_generator(X_train, y_train, 500):\n",
    "            # На лекции мы рассказывали, что дропаут работает по-разному во время обучения и реального предсказания\n",
    "            # Чтобы это учесть нам нужно включать и выключать режим обучения, делается это командой ниже\n",
    "            model.train(True)\n",
    "            \n",
    "            # Посчитаем предсказание и лосс\n",
    "            <YOUR CODE>\n",
    "            \n",
    "            # зануляем градиент\n",
    "            <YOUR CODE>\n",
    "\n",
    "            # backward\n",
    "            <YOUR CODE>\n",
    "\n",
    "            # ОБНОВЛЯЕМ веса \n",
    "            <YOUR CODE>\n",
    "            \n",
    "            # Запишем число (не тензор) в наши батчевые лоссы\n",
    "            train_losses.append(<YOUR CODE>)\n",
    "            \n",
    "            # Теперь посчитаем лосс на тесте\n",
    "            model.train(False)\n",
    "            # Сюда опять же надо положить именно число равное лоссу на всем тест датасете\n",
    "            test_losses.append(<YOUR CODE>)\n",
    "            \n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cDyg5zMckQOX",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_losses, test_losses = train(20)\n",
    "plt.scatter(range(len(train_losses)), train_losses)\n",
    "plt.scatter(range(len(test_losses)), test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4nomCVu0kQOa"
   },
   "outputs": [],
   "source": [
    "# Ответ на задачу\n",
    "model.train(False)\n",
    "<Ваш код>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IB1XswA2kQOd"
   },
   "source": [
    "# Задание 3\n",
    "\n",
    "Только что вы обучили полносвязную нейронку, сейчас попробуйте исправить ошибки в созданных ниже нейронках и потом обучить их с помощью той же функции train. Будьте осторожнее и убедитесь, что перед запуском train вы вновь переопределили все необходимые внешние переменные (train обращается к глобальным переменным, в целом так делать не стоит, но сейчас это было оправдано, так как иначе нам пришлось бы передавать порядка 7-8 аргументов).\n",
    "\n",
    "Чтобы у вас получилась такая же архитектура, как у нас, и ответы совпали, давайте определим некоторые правила, как исправлять ошибки:\n",
    "\n",
    "1. Если вы видите лишний не линейный слой, который стоит не на своем месте, просто удалите его. (не нужно добавлять новые слои, чтобы сдлеать постановку изначального слоя разумной. Удалять надо самый последний слой, который все портит. Для линейных слоев надо что-то исправить, а не удалить его)\n",
    "2. Если у слоя нет активации, то добавьте ReLU или другую подходящую активацию\n",
    "3. Если что-то не так с learning_rate, то поставьте 1e-2\n",
    "4. Если что-то не так с параметрами, считайте первый параметр, который появляется, как верный (т.е. далее в сети должен использоваться он).\n",
    "5. Ошибки могут быть и в полносвязных слоях. \n",
    "6. Любые другие проблемы решаются более менее однозначно, если же у вас есть серьезные сомнения, то напишите в беседу в телеграме и пинганите меня @runfme\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Un7PyM39kQOe"
   },
   "source": [
    "Задача все та же - классификация небесных объектов на том же датасете. После исправления сети вам нужно обучить ее.\n",
    "\n",
    "**Ответ на задачу - средний лосс на тестовом датасете**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3M9P67WekQOe"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)   \n",
    "np.random.seed(42)\n",
    "# WRONG ARCH\n",
    "model = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(6, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(100, 200),\n",
    "    nn.Softmax(),\n",
    "    nn.Linear(200, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(200, 3),\n",
    "    nn.Dropout(p=0.5)\n",
    ")\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters[:-2], lr=1e-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T0HEx6vbkQOi"
   },
   "outputs": [],
   "source": [
    "# RIGHT ARCH\n",
    "torch.manual_seed(42)   \n",
    "np.random.seed(42)\n",
    "model = nn.Sequential(\n",
    "    <YOUR CODE>\n",
    ")\n",
    "\n",
    "\n",
    "loss_fn = <YOUR CODE>\n",
    "optimizer = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lKT-usCrkQOl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses, test_losses = train(20)\n",
    "plt.scatter(range(len(train_losses)), train_losses)\n",
    "plt.scatter(range(len(test_losses)), test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7SZv9yARkQOo"
   },
   "outputs": [],
   "source": [
    "# Ответ на задачу \n",
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bUGWpT3MkQOr"
   },
   "source": [
    "# Задание 4\n",
    "\n",
    "А теперь просто задание на интерес, давайте посмотрим, когда добавление перестает улучшать метрики. Увеличивайте блоков из слоев в сети, пока минимальный лосс на тестовом датасете за все время обучения не перестанет уменьшаться (20 эпох). Ответ - целое число, количество блоков, такое, что при добавлении еще одного блока минимальный лосс за время обучения увеличиться (строго).\n",
    "\n",
    "А еще стоит помнить, что нельзя переиспользовать слои с предыдущих обучений, потому что они уже будут с подобранными весами.\n",
    "\n",
    "**Чтобы получить воспроизводимость и идентичный нашему ответ, надо объявлять все слои в порядке, в котором они применяются внутри модели. Это важно, если вы будете собирать свою модель из частей. Перед объявлением этих слоев по порядку напишите**\n",
    "> torch.manual_seed(42)   \n",
    "> np.random.seed(42)\n",
    "\n",
    "**При чем каждый раз, когда вы заново создаете модель, перезадавайте random seeds**\n",
    "\n",
    "**Опитимизатор - Adam(lr=1e-2)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JZzgn9y8kQOr"
   },
   "outputs": [],
   "source": [
    "# МОДЕЛЬ ДЛЯ ПРИМЕРА, НА САМОМ ДЕЛЕ ВАМ ПРИДЕТСЯ СОЗДАВАТЬ НОВУЮ МОДЕЛЬ ДЛЯ КАЖДОГО КОЛИЧЕСТВА БЛОКОВ\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(len(feature_columns), 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    # Начало блока, который надо вставалять много раз\n",
    "    nn.Linear(100, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(100),\n",
    "    # Конец блока\n",
    "    nn.Linear(100, 3)\n",
    "    # Блока Softmax нет, поэтому нам нужно использовать лосс - CrossEntropyLoss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yYUngAvSkQOw",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Вы уже многое умеете, поэтому теперь код надо написать самому\n",
    "# Идея - разделить модель на части.\n",
    "# Вначале создать head часть как Sequential модель, потом в цикле создать Sequential модели, которые представляют\n",
    "# из себя блоки, потом создать tail часть тоже как Sequential, а потом объединить их в одну Sequential модель \n",
    "# вот таким кодом: nn.Sequential(header, *blocks, footer)\n",
    "# Важная идея тут состоит в том, что модели могут быть частями других моделей)\n",
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZkHdcxJskQO1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBy7CcXZkQO3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[homework]7_neural_nerworks.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
